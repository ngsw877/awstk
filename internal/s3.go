package internal

import (
	"compress/gzip"
	"context"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/aws/aws-sdk-go-v2/service/s3/types"
)

// ListS3Buckets ã¯S3ãƒã‚±ãƒƒãƒˆåã®ä¸€è¦§ã‚’è¿”ã™é–¢æ•°
func ListS3Buckets(region, profile string) ([]string, error) {
	cfg, err := LoadAwsConfig(region, profile)
	if err != nil {
		return nil, err
	}

	// Create an Amazon S3 service client
	client := s3.NewFromConfig(cfg)

	// List all S3 buckets
	result, err := client.ListBuckets(context.TODO(), &s3.ListBucketsInput{})
	if err != nil {
		return nil, err
	}

	buckets := make([]string, 0, len(result.Buckets))
	for _, bucket := range result.Buckets {
		buckets = append(buckets, *bucket.Name)
	}
	return buckets, nil
}

// getS3BucketsByKeyword ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ï¿½ï¿½ï¿½S3ãƒã‚±ãƒƒãƒˆåã®ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™
func getS3BucketsByKeyword(opts CleanupOptions) ([]string, error) {
	cfg, err := LoadAwsConfig(opts.Region, opts.Profile)
	if err != nil {
		return nil, fmt.Errorf("AWSè¨­å®šã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
	s3Client := s3.NewFromConfig(cfg)

	// ãƒã‚±ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—
	listBucketsOutput, err := s3Client.ListBuckets(context.TODO(), &s3.ListBucketsInput{})
	if err != nil {
		return nil, fmt.Errorf("S3ãƒã‚±ãƒƒãƒˆä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	foundBuckets := []string{}
	for _, bucket := range listBucketsOutput.Buckets {
		if strings.Contains(*bucket.Name, opts.SearchString) {
			foundBuckets = append(foundBuckets, *bucket.Name)
			fmt.Printf("ğŸ” æ¤œå‡ºã•ã‚ŒãŸS3ãƒã‚±ãƒƒãƒˆ: %s\n", *bucket.Name)
		}
	}

	return foundBuckets, nil
}

// cleanupS3Buckets ã¯æŒ‡å®šã—ãŸS3ãƒã‚±ãƒƒãƒˆä¸€è¦§ã‚’å‰Šé™¤ã—ã¾ã™
func cleanupS3Buckets(opts CleanupOptions, bucketNames []string) error {
	cfg, err := LoadAwsConfig(opts.Region, opts.Profile)
	if err != nil {
		return fmt.Errorf("AWSè¨­å®šã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
	s3Client := s3.NewFromConfig(cfg)

	for _, bucket := range bucketNames {
		fmt.Printf("ãƒã‚±ãƒƒãƒˆ %s ã‚’ç©ºã«ã—ã¦å‰Šé™¤ä¸­...\n", bucket)

		// ãƒã‚±ãƒƒãƒˆã‚’ç©ºã«ã™ã‚‹ (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å¯¾å¿œ)
		err := emptyS3Bucket(s3Client, bucket)
		if err != nil {
			fmt.Printf("âŒ ãƒã‚±ãƒƒãƒˆ %s ã‚’ç©ºã«ã™ã‚‹ã®ã«å¤±æ•—ã—ã¾ã—ãŸ: %v\n", bucket, err)
			// ã“ã®ãƒã‚±ãƒƒãƒˆã®å‰Šé™¤ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ¬¡ã®ãƒã‚±ãƒƒãƒˆã¸
			continue
		}

		// ãƒã‚±ãƒƒãƒˆã®å‰Šé™¤
		fmt.Printf("  ãƒã‚±ãƒƒãƒˆå‰Šé™¤ä¸­: %s\n", bucket)
		_, err = s3Client.DeleteBucket(context.TODO(), &s3.DeleteBucketInput{
			Bucket: aws.String(bucket),
		})
		if err != nil {
			fmt.Printf("âŒ ãƒã‚±ãƒƒãƒˆ %s ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: %v\n", bucket, err)
			// ã“ã®ãƒã‚±ãƒƒãƒˆã®å‰Šé™¤ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ¬¡ã®ãƒã‚±ãƒƒãƒˆã¸
			continue
		}
	}
	return nil
}

// emptyS3Bucket ã¯æŒ‡å®šã—ãŸS3ãƒã‚±ãƒƒãƒˆã®ä¸­èº«ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã™ (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å¯¾å¿œ)
func emptyS3Bucket(s3Client *s3.Client, bucketName string) error {
	// ãƒã‚±ãƒƒãƒˆå†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒªã‚¹ãƒˆ
	listVersionsOutput, err := s3Client.ListObjectVersions(context.TODO(), &s3.ListObjectVersionsInput{
		Bucket: aws.String(bucketName),
	})
	if err != nil {
		return fmt.Errorf("ãƒã‚±ãƒƒãƒˆå†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// å‰Šé™¤å¯¾è±¡ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨å‰Šé™¤ãƒãƒ¼ã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
	deleteObjects := []types.ObjectIdentifier{}
	if listVersionsOutput.Versions != nil {
		for _, version := range listVersionsOutput.Versions {
			deleteObjects = append(deleteObjects, types.ObjectIdentifier{
				Key:       version.Key,
				VersionId: version.VersionId,
			})
		}
	}
	if listVersionsOutput.DeleteMarkers != nil {
		for _, marker := range listVersionsOutput.DeleteMarkers {
			deleteObjects = append(deleteObjects, types.ObjectIdentifier{
				Key:       marker.Key,
				VersionId: marker.VersionId,
			})
		}
	}

	// å‰Šé™¤å¯¾è±¡ãŒãªã‘ã‚Œã°çµ‚äº†
	if len(deleteObjects) == 0 {
		fmt.Println("  å‰Šé™¤ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
		return nil
	}

	// ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¸€æ‹¬å‰Šé™¤ (æœ€å¤§1000å€‹ãšã¤)
	chunkSize := 1000
	for i := 0; i < len(deleteObjects); i += chunkSize {
		end := i + chunkSize
		if end > len(deleteObjects) {
			end = len(deleteObjects)
		}
		batch := deleteObjects[i:end]

		fmt.Printf("  %dä»¶ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤ä¸­...\n", len(batch))
		_, err = s3Client.DeleteObjects(context.TODO(), &s3.DeleteObjectsInput{
			Bucket: aws.String(bucketName),
			Delete: &types.Delete{
				Objects: batch,
				Quiet:   aws.Bool(false),
			},
		})
		if err != nil {
			return fmt.Errorf("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ‹¬å‰Šé™¤ã‚¨ãƒ©ãƒ¼: %w", err)
		}
		// TODO: DeleteObjectsã®Errorsã‚’ç¢ºèªã—ã¦å‡¦ç†ã‚’æ¤œè¨
	}

	// ã¾ã ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯å†å¸°çš„ã«å‘¼ã³å‡ºã™ï¼ˆNextTokenå¯¾å¿œã¯ä¸€æ—¦ã—ãªã„ï¼‰
	// ç°¡æ˜“çš„ãªå¯¾å¿œã®ãŸã‚ã€å‰Šé™¤å¾Œã«å†åº¦ãƒªã‚¹ãƒˆã—ã¦ç©ºã«ãªã‚‹ã¾ã§ç¹°ã‚Šè¿”ã™ï¼ˆéåŠ¹ç‡ã ãŒã‚·ãƒ³ãƒ—ãƒ«ï¼‰
	// å®Ÿéš›ã«ã¯ListObjectVersionsã®NextTokenã‚’ä½¿ã†ã®ãŒæ­£ã—ã„ãŒã€ä»Šå›ã¯ç°¡æ˜“å®Ÿè£…
	// TODO: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ
	time.Sleep(1 * time.Second) // åæ˜ ã‚’å¾…ã¤
	remainingObjects, err := s3Client.ListObjectVersions(context.TODO(), &s3.ListObjectVersionsInput{
		Bucket: aws.String(bucketName),
	})
	if err != nil {
		return fmt.Errorf("å‰Šé™¤å¾Œã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç¢ºèªã‚¨ãƒ©ãƒ¼: %w", err)
	}

	if len(remainingObjects.Versions) > 0 || len(remainingObjects.DeleteMarkers) > 0 {
		// æ®‹ã£ã¦ã„ã‚‹å ´åˆã¯å†åº¦ç©ºã«ã™ã‚‹å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆç°¡æ˜“çš„ãªå†å¸°ï¼‰
		// ç„¡é™ãƒ«ãƒ¼ãƒ—ã«ãªã‚‰ãªã„ã‚ˆã†ã«æ³¨æ„ãŒå¿…è¦ã ãŒã€ã“ã“ã§ã¯å˜ç´”åŒ–
		return emptyS3Bucket(s3Client, bucketName) // ç°¡æ˜“çš„ãªå†å¸°å‘¼ã³å‡ºã—
	}

	return nil
}

// DownloadAndExtractGzFiles æŒ‡å®šS3ãƒ‘ã‚¹é…ä¸‹ã®.gzãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼†è§£å‡
func DownloadAndExtractGzFiles(s3url, outDir, region, profile string) error {
	ctx := context.Background()
	cfg, err := LoadAwsConfig(region, profile)
	if err != nil {
		return fmt.Errorf("AWSè¨­å®šã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: %w", err)
	}
	bucket, prefix, err := parseS3Url(s3url)
	if err != nil {
		return err
	}
	client := s3.NewFromConfig(cfg)
	// .gzãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
	listInput := &s3.ListObjectsV2Input{
		Bucket: &bucket,
		Prefix: &prefix,
	}
	resp, err := client.ListObjectsV2(ctx, listInput)
	if err != nil {
		return fmt.Errorf("S3ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: %w", err)
	}
	if len(resp.Contents) == 0 {
		return fmt.Errorf("æŒ‡å®šãƒ‘ã‚¹ã«.gzãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
	}
	for _, obj := range resp.Contents {
		if !strings.HasSuffix(*obj.Key, ".gz") {
			continue
		}
		getObjInput := &s3.GetObjectInput{
			Bucket: &bucket,
			Key:    obj.Key,
		}
		getObjOut, err := client.GetObject(ctx, getObjInput)
		if err != nil {
			return fmt.Errorf("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: %w", err)
		}
		defer getObjOut.Body.Close()
		// ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ç”Ÿæˆ
		relPath := strings.TrimPrefix(*obj.Key, prefix)
		if strings.HasPrefix(relPath, "/") {
			relPath = relPath[1:]
		}
		outPath := filepath.Join(outDir, strings.TrimSuffix(relPath, ".gz"))
		if err := os.MkdirAll(filepath.Dir(outPath), 0755); err != nil {
			return fmt.Errorf("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå¤±æ•—: %w", err)
		}
		// è§£å‡ã—ã¦ä¿å­˜
		gzr, err := gzip.NewReader(getObjOut.Body)
		if err != nil {
			return fmt.Errorf("gzipè§£å‡å¤±æ•—: %w", err)
		}
		f, err := os.Create(outPath)
		if err != nil {
			return fmt.Errorf("ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: %w", err)
		}
		_, err = io.Copy(f, gzr)
		gzr.Close()
		f.Close()
		if err != nil {
			return fmt.Errorf("ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿å¤±æ•—: %w", err)
		}
		fmt.Printf("âœ… %s ã‚’ %s ã«ä¿å­˜ã—ã¾ã—ãŸ\n", *obj.Key, outPath)
	}
	return nil
}

// parseS3Url s3://bucket/prefix/ å½¢å¼ã‚’åˆ†è§£
func parseS3Url(s3url string) (bucket, prefix string, err error) {
	if !strings.HasPrefix(s3url, "s3://") {
		return "", "", fmt.Errorf("âš ï¸ S3ãƒ‘ã‚¹ã¯ s3:// ã§å§‹ã‚ã¦ãã ã•ã„")
	}
	noPrefix := strings.TrimPrefix(s3url, "s3://")
	parts := strings.SplitN(noPrefix, "/", 2)
	bucket = parts[0]
	if len(parts) > 1 {
		prefix = parts[1]
	} else {
		prefix = ""
	}
	if prefix != "" && !strings.HasSuffix(prefix, "/") {
		prefix += "/"
	}
	return bucket, prefix, nil
}
